{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Densenet121_CheXpert_NIH.ipynb",
      "provenance": [],
      "mount_file_id": "1hWs6CKl7zu-yhcY3NFoVYQk1DCBd-2lH",
      "authorship_tag": "ABX9TyPICzB9daRrAYkzZME74L0M",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "b1d08d5abcf8498e84382694767f13b1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_f2b619c707e44efba4545171adca3aa8",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_b286a69962b7409695423119afeef210",
              "IPY_MODEL_e5e23a253ef44204b7a8bb87c9e0bd03",
              "IPY_MODEL_8c0b3ff7fe934806a86378132e8645e6"
            ]
          }
        },
        "f2b619c707e44efba4545171adca3aa8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "b286a69962b7409695423119afeef210": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_a151833ff090442eab9ac5dc3385ed4d",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_072978a6bcc14085957ac85ff0b23f75"
          }
        },
        "e5e23a253ef44204b7a8bb87c9e0bd03": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_35107212a856434aa7c178de06c05244",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 32342954,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 32342954,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_5158413678aa4b4daf1547930418316e"
          }
        },
        "8c0b3ff7fe934806a86378132e8645e6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_79b29cd430604617966bafd88d41aeee",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 30.8M/30.8M [00:03&lt;00:00, 24.1MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_08e3220a6c534a6abb419fe8eea2b926"
          }
        },
        "a151833ff090442eab9ac5dc3385ed4d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "072978a6bcc14085957ac85ff0b23f75": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "35107212a856434aa7c178de06c05244": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "5158413678aa4b4daf1547930418316e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "79b29cd430604617966bafd88d41aeee": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "08e3220a6c534a6abb419fe8eea2b926": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sisifo3/P_T_3/blob/main/Densenet121_CheXpert_NIH.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "6d05AJa3_6NE"
      },
      "outputs": [],
      "source": [
        "!tar -xf /content/drive/MyDrive/NIH_Dataset_total/images_001.tar.gz\n",
        "#!tar -xf /content/drive/MyDrive/NIH_Dataset_total/images_002.tar.gz\n",
        "#!tar -xf /content/drive/MyDrive/NIH_Dataset_total/images_003.tar.gz\n",
        "#!tar -xf /content/drive/MyDrive/NIH_Dataset_total/images_004.tar.gz\n",
        "#!tar -xf /content/drive/MyDrive/NIH_Dataset_total/images_005.tar.gz\n",
        "#!tar -xf /content/drive/MyDrive/NIH_Dataset_total/images_006.tar.gz\n",
        "#!tar -xf /content/drive/MyDrive/NIH_Dataset_total/images_007.tar.gz\n",
        "#!tar -xf /content/drive/MyDrive/NIH_Dataset_total/images_008.tar.gz\n",
        "#!tar -xf /content/drive/MyDrive/NIH_Dataset_total/images_009.tar.gz\n",
        "#!tar -xf /content/drive/MyDrive/NIH_Dataset_total/images_010.tar.gz\n",
        "#!tar -xf /content/drive/MyDrive/NIH_Dataset_total/images_011.tar.gz\n",
        "#!tar -xf /content/drive/MyDrive/NIH_Dataset_total/images_012.tar.gz"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip /content/drive/MyDrive/NIH_dataset/CheXpert-v1.0-small-1.zip "
      ],
      "metadata": {
        "id": "po5kB-bzAEVk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "from scipy.ndimage.filters import gaussian_filter\n",
        "from scipy.ndimage.interpolation import map_coordinates\n",
        "random_state = np.random.RandomState(0)\n",
        "\n",
        "def clahe(image_name):\n",
        "    image = cv2.imread(image_name, 0)\n",
        "    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))\n",
        "    he_img = clahe.apply(image)\n",
        "    image = cv2.cvtColor(he_img, cv2.COLOR_GRAY2RGB)\n",
        "    return Image.fromarray(image)\n"
      ],
      "metadata": {
        "id": "fl-X6CqKAGMR"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision import transforms\n",
        "import torch\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "\n",
        "'''\n",
        "cropSize = 320\n",
        "\n",
        "#for NIh dataset\n",
        "transform = transforms.Compose([\n",
        "                    #transforms.RandomResizedCrop(cropSize),\n",
        "                    transforms.Resize((320, 320)),\n",
        "                    transforms.RandomHorizontalFlip(),\n",
        "                    transforms.RandomRotation(10),\n",
        "                    transforms.ToTensor(),\n",
        "                    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n",
        "                    ])\n",
        "'''"
      ],
      "metadata": {
        "id": "5wP8waBBAIvO"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision import transforms\n",
        "import torch\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "\n",
        "#for CheXpert\n",
        "transform = transforms.Compose([\n",
        "                                transforms.Resize((320, 320)),\n",
        "                                transforms.ToTensor(),\n",
        "                                transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n",
        "                                ])"
      ],
      "metadata": {
        "id": "hK-5bl4jAJTx"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "\n",
        "def getImagesLabels(filename):\n",
        "\n",
        "    df = pd.read_csv(filename)\n",
        "    relevant_cols = ['path','No Finding', 'Enlarged Cardiomediastinum', 'Cardiomegaly',\n",
        "                    'Lung Opacity', 'Lung Lesion', 'Edema',  'Consolidation',\n",
        "                    'Pneumonia', 'Atelectasis','Pneumothorax', 'Pleural Effusion',\n",
        "                    'Pleural Other', 'Fracture', 'Support Devices','Hernia','Mass',\n",
        "                    'Fibrosis','Infiltration','Nodule','Emphysema','Pleural_Thickening']\n",
        "\n",
        "\n",
        "    df = df[relevant_cols]\n",
        "    df = df.replace(np.nan, 0.0)\n",
        "\n",
        "    df = df.replace(-1.0, 0.0)\n",
        "\n",
        "\n",
        "    X = df['path']\n",
        "    y = df[['No Finding', 'Enlarged Cardiomediastinum', 'Cardiomegaly',\n",
        "                    'Lung Opacity', 'Lung Lesion', 'Edema',  'Consolidation',\n",
        "                    'Pneumonia', 'Atelectasis','Pneumothorax', 'Pleural Effusion',\n",
        "                    'Pleural Other', 'Fracture', 'Support Devices','Hernia','Mass',\n",
        "                    'Fibrosis','Infiltration','Nodule','Emphysema','Pleural_Thickening']]\n",
        "\n",
        "    return np.asarray(X), np.asarray(y)\n",
        "\n",
        "\n",
        "\n",
        "#filename = '/content/drive/MyDrive/NIH_Dataset_total/final_cheXpert_NIH_train.csv'\n",
        "#x1, y1 = getImagesLabels(filename)"
      ],
      "metadata": {
        "id": "5WhJ5qPVASlu"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "def getExistValues(train_images, train_labels):\n",
        "  val2 = ['done first']\n",
        "  val2 = np.array(val2)\n",
        "  val3 = [0]*21\n",
        "  val3= [float(item) for item in val3]\n",
        "  val3 = np.array(val3)\n",
        "\n",
        "  i = 0\n",
        "\n",
        "  for val in train_images:\n",
        "    path = val\n",
        "    isExist = os.path.exists(path)\n",
        "    if isExist == True:\n",
        "      val2 = np.append(val2, val)\n",
        "      val3 = np.vstack([val3, train_labels[i]])\n",
        "    i = i + 1\n",
        "\n",
        "\n",
        "  val2 = np.delete(val2,0)\n",
        "  val3 = np.delete(val3, 0, axis=0)\n",
        "\n",
        "  return  np.asarray(val2), np.asarray(val3)\n",
        "\n"
      ],
      "metadata": {
        "id": "xwrtwkoDAbld"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CheXpertDataset(Dataset):\n",
        "    def __init__(self, image_list, labels, transform=None, test=False):\n",
        "        self.image_names = image_list\n",
        "        self.labels = labels\n",
        "        self.transform = transform\n",
        "        self.test = test\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        image_name = self.image_names[index]\n",
        "        image = clahe(image_name)\n",
        "        label = self.labels[index]\n",
        "        image = self.transform(image)\n",
        "        return image, torch.FloatTensor(label)\n",
        "\n",
        "    def __len__(self):\n",
        "       \n",
        "        return len(self.image_names)"
      ],
      "metadata": {
        "id": "X4_2GQyPAeGM"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import  torchvision\n",
        "import torch.nn as nn\n",
        "from torchsummary import summary\n",
        "\n",
        "class DenseNet121(nn.Module):\n",
        "\n",
        "    def __init__(self, out_size, test=False):\n",
        "        super(DenseNet121, self).__init__()\n",
        "        self.test = test\n",
        "        self.densenet121 = torchvision.models.densenet121(pretrained=True)\n",
        "        num_ftrs = self.densenet121.classifier.in_features\n",
        "        self.densenet121.classifier = nn.Sequential(\n",
        "            nn.Linear(num_ftrs, num_ftrs),\n",
        "            nn.BatchNorm1d(num_ftrs),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout(0.5),\n",
        "            nn.Linear(num_ftrs, num_ftrs//2),\n",
        "            nn.BatchNorm1d(num_ftrs//2),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout(0.25),\n",
        "            nn.Linear(num_ftrs//2, out_size),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.densenet121(x)\n",
        "\n",
        "        if self.test:\n",
        "            return torch.sigmoid(x)\n",
        "        else:\n",
        "            return x\n"
      ],
      "metadata": {
        "id": "E6VEkXBiAolU"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch import optim\n",
        "from torch.optim.lr_scheduler import ReduceLROnPlateau, StepLR\n",
        "from datetime import datetime\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "\n",
        "class Trainer():\n",
        "    def __init__(self, model, train_loader, val_loader):\n",
        "        self.model = model\n",
        "        self.train_loader = train_loader\n",
        "        self.val_loader = val_loader\n",
        "\n",
        "        self.losses = {'train':[], 'validation':[]}\n",
        "\n",
        "\n",
        "    def compile(self, lr, loss_fn, scheduler=False):\n",
        "        \n",
        "        self.learning_rate = lr\n",
        "        self.optimizer = optim.Adam(self.model.parameters(), lr=lr, betas=(0.9, 0.999), eps=1e-08, weight_decay=1e-5)\n",
        "        self.loss_fn = loss_fn\n",
        "\n",
        "        if (scheduler):\n",
        "            self.scheduler = ReduceLROnPlateau(self.optimizer, mode='min', factor=0.1, patience=2, verbose=True, min_lr=1e-6)\n",
        "  \n",
        "    def load_checkpoint(self, log_path, model_path):\n",
        "        \"\"\" Function to load checkpoints from a previously saved model\n",
        "        Arguments:\n",
        "            log_path : path to saved log file\n",
        "            model_path : path to saved model\n",
        "        Returns:\n",
        "            start_epoch : the epoch from which to resume the training\n",
        "            model : the model with loaded weights\n",
        "            optimizer : the optimizer with the previous state\n",
        "            scheduler : the scheduler with the previous state\n",
        "            losses : the dictionary populated with loss values from previous epochs\n",
        "        \"\"\"\n",
        "        # Note: Input model & optimizer should be pre-defined. This routine only updates their states\n",
        "        start_epoch = 0\n",
        "\n",
        "        self.log_path = log_path\n",
        "        self.model_path = model_path\n",
        "\n",
        "        print(self.log(\"\\nLoading checkpoint from '{}'\\n\".format(model_path)))\n",
        "\n",
        "        checkpoint = torch.load(model_path)\n",
        "        start_epoch = checkpoint['epoch'] + 1\n",
        "        self.model.load_state_dict(checkpoint['model_state_dict'])\n",
        "        self.optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "\n",
        "        try:\n",
        "            self.scheduler.load_state_dict(checkpoint['scheduler_state_dict'])\n",
        "        except:\n",
        "            pass\n",
        "\n",
        "        self.losses = checkpoint['loss']\n",
        "        val_min = min(self.losses['validation'])\n",
        "\n",
        "        print(self.log(\"--> Loaded checkpoint from '{}'\\nResuming training from epoch {}\\n\\n\"\n",
        "                    .format(model_path, start_epoch)))\n",
        "\n",
        "        return start_epoch, self.model, self.optimizer, self.scheduler, self.losses, val_min\n",
        "        # return start_epoch, self.model, self.optimizer, self.losses, val_min\n",
        "\n",
        "\n",
        "    def epoch_train(self, print_every=50):\n",
        "        model = self.model\n",
        "        loss_fn = self.loss_fn\n",
        "        optimizer = self.optimizer\n",
        "        #device = self.device\n",
        "        print(\"trainin 2\")\n",
        "        train_loss = 0.0\n",
        "        model.train()\n",
        "        for batch_idx, (data, target) in enumerate(self.train_loader):\n",
        "            #print(target)\n",
        "            #print(data)  \n",
        "            data, target = data.float().to(device), target.float().to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            pred = model(data)\n",
        "            loss = loss_fn(pred, target)\n",
        "\n",
        "            train_loss += ((1 / (batch_idx + 1)) * (loss.item()/data.size(0) - train_loss))\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            if (batch_idx % print_every == 0):\n",
        "                print('Epoch {}\\tBatch [{}/{}]\\t\\tTraining Loss: {}'.format(self.epoch+1, batch_idx+1, len(self.train_loader), train_loss))\n",
        "\n",
        "        return train_loss\n",
        "\n",
        "    def epoch_val(self):\n",
        "        model = self.model\n",
        "        loss_fn = self.loss_fn\n",
        "        #device = self.device\n",
        "\n",
        "        valid_loss = 0.0\n",
        "        model.eval()\n",
        "        with torch.no_grad():\n",
        "            for batch_idx, (data, target) in enumerate(self.val_loader):\n",
        "                data, target = data.float().to(device), target.float().to(device)\n",
        "\n",
        "                val_pred = model(data)\n",
        "                val_loss = loss_fn(val_pred, target)\n",
        "\n",
        "                valid_loss += ((1 / (batch_idx + 1)) * (val_loss.item()/data.size(0) - valid_loss))\n",
        "\n",
        "        return valid_loss\n",
        "\n",
        "    def train(self, n_epochs, batch_size, log_path=None, model_path=None):\n",
        "  \n",
        "        start = datetime.now()\n",
        "\n",
        "        model = self.model\n",
        "        optimizer = self.optimizer\n",
        "        try:\n",
        "            scheduler = self.scheduler\n",
        "        except:\n",
        "            pass\n",
        "        losses = self.losses\n",
        "        valid_loss_min = np.Inf\n",
        "        start_epoch = 0\n",
        "\n",
        "        if (log_path is None and model_path is None):\n",
        "            self.log_path = str(start.strftime('%d-%m-%Y-%H:%M:%S')+'_train_log')\n",
        "            self.model_path = '{}_model.pt'.format(start.strftime('%d-%m-%Y-%H:%M:%S'))\n",
        "            self.log('Learning rate: {}, Batch size: {}\\n\\n'.format(self.learning_rate, batch_size))\n",
        "\n",
        "        elif (os.path.exists(model_path) and os.path.exists(log_path)):\n",
        "            # start_epoch, model, optimizer, scheduler, losses = self.load_checkpoint(log_path, model_path)\n",
        "            start_epoch, model, optimizer, scheduler, losses, valid_loss_min = self.load_checkpoint(log_path, model_path)\n",
        "            valid_loss_min = min(losses['validation'])\n",
        "\n",
        "        else:\n",
        "            print('[!] Specified model path or log path does not exist.')\n",
        "            return\n",
        "\n",
        "        # loss_fn = self.loss_fn\n",
        "\n",
        "        \n",
        "\n",
        "        checkpoint = {}\n",
        "\n",
        "        for self.epoch in range(start_epoch, start_epoch+n_epochs):\n",
        "\n",
        "            #print(\"we start trinning\")\n",
        "            train_loss = self.epoch_train(print_every=500)\n",
        "\n",
        "            valid_loss = self.epoch_val()\n",
        "\n",
        "            print(self.log('\\nEpoch: [{}/{}] \\tTraining Loss: {:.5f} \\tValidation Loss: {:.5f}\\n'.format(\n",
        "                                                    self.epoch+1, start_epoch+n_epochs, train_loss, valid_loss)))\n",
        "            print('-'*100)\n",
        "\n",
        "                 #####----CHECKPOINTING----#####\n",
        "            if (valid_loss < valid_loss_min):\n",
        "                print(self.log(\"Saving model.  Validation loss:... {:.5f} --> {:.5f}\\n\".format(valid_loss_min, valid_loss)))\n",
        "                print('*'*100)\n",
        "                valid_loss_min = valid_loss\n",
        "\n",
        "                checkpoint['model_state_dict'] = model.state_dict()\n",
        "                checkpoint['optimizer_state_dict'] = optimizer.state_dict()\n",
        "                try:\n",
        "                    checkpoint['scheduler_state_dict'] = scheduler.state_dict()\n",
        "                except:\n",
        "                    pass\n",
        "                print()\n",
        "\n",
        "            try:\n",
        "                scheduler.step(valid_loss)\n",
        "            except:\n",
        "                pass\n",
        "\n",
        "            losses['train'].append(train_loss)\n",
        "            losses['validation'].append(valid_loss)\n",
        "\n",
        "            checkpoint['epoch'] = self.epoch\n",
        "            checkpoint['loss'] = losses\n",
        "            torch.save(checkpoint, self.model_path)\n",
        "\n",
        "            self.draw_loss_curve('{}_losses.png'.format(self.model_path.split('_')[0]))\n",
        "\n",
        "        end = datetime.now()\n",
        "        time = str(end - start).split('.')[0]\n",
        "        print(self.log(\"\\nCompleted training in {}\\n\".format(time)))\n",
        "\n",
        "        return model, losses\n",
        "\n",
        "    def log(self, info):\n",
        "        \"\"\" Function to create and update the log file\n",
        "        Arguments:\n",
        "            info : the update information to write on the log file\n",
        "        Returns:\n",
        "            info : the logged information to be printed while training\n",
        "        \"\"\"\n",
        "        log_path = self.log_path\n",
        "\n",
        "        if not os.path.exists(log_path):\n",
        "            file = open(log_path, 'w')\n",
        "            file.write(info)\n",
        "            file.close()\n",
        "        else:\n",
        "            file = open(log_path, 'a')\n",
        "            file.write(info)\n",
        "            file.close()\n",
        "\n",
        "        return info.strip('\\n')\n",
        "\n",
        "    def draw_loss_curve(self, fpath, losses=None):\n",
        "        \"\"\" Function to generate loss curve for the training process\n",
        "        Arguments:\n",
        "            fpath : the filepath to save the loss curve in\n",
        "        \"\"\"\n",
        "        if losses is None:\n",
        "            losses = self.losses\n",
        "        # plt.ylim([0,2])\n",
        "        plt.plot(losses['train'], label='Training loss')\n",
        "        plt.plot(losses['validation'], label='Validation loss')\n",
        "        plt.legend()\n",
        "        plt.savefig(fpath)\n",
        "        # plt.show()\n",
        "        plt.close()  "
      ],
      "metadata": {
        "id": "zkCxViK_AwwT"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import math\n",
        "\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "\n",
        "train_csv = '/content/drive/MyDrive/NIH_Dataset_total/final_Only_cheXpert_train.csv'\n",
        "#train_csv = '/content/drive/MyDrive/NIH_Dataset_total/final_Only_NIH_train.csv'\n",
        "\n",
        "train_images, train_labels = getImagesLabels(train_csv)\n",
        "\n",
        "##########################################3\n",
        "#train_images, train_labels = getExistValues(train_images, train_labels)\n",
        "\n",
        "l = len(train_images)\n",
        "n = math.floor(l - (l * .2))\n",
        "print(n)\n",
        "#########################\n",
        "\n",
        "#train = 268000\n",
        "#val = 67000\n",
        "\n",
        "val_images, val_labels = train_images[n+1:], train_labels[n+1:]\n",
        "train_images, train_labels = train_images[:n], train_labels[:n]\n",
        "\n",
        "print('No. of images:\\n\\t|--Training: {}\\n\\t|--Validation: {}\\n'.format(len(train_images), len(val_images)))\n",
        "\n",
        "train_dataset = CheXpertDataset(train_images, train_labels, transform)\n",
        "val_dataset = CheXpertDataset(val_images, val_labels, transform)\n",
        "\n",
        "### hyperparameters ###\n",
        "batchSize = 4\n",
        "lr = 0.0001\n",
        "epochs = 1\n",
        "num_classes = 21\n",
        "\n",
        "### data loaders ###\n",
        "train_loader = DataLoader(train_dataset, batch_size=batchSize, shuffle=True,  num_workers=2, pin_memory=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=batchSize, shuffle=False,  num_workers=2, pin_memory=True)\n",
        "\n",
        "### initializing the model ###\n",
        "model = DenseNet121(num_classes)\n",
        "model = torch.nn.DataParallel(model)\n",
        "#model.cuda()\n",
        "\n",
        "### training ###\n",
        "trainer = Trainer(model, train_loader, val_loader)\n",
        "\n",
        "# moving the model to device\n",
        "model.to(device)\n",
        "\n",
        "\n",
        "pos_weights = [3.059119740473539, 28.90637155028709, 9.992811313782795, 2.1230429717468104, 35.34269540605269, 4.909329226933583,\n",
        "14.824158864080667, 41.38345159994645, 5.714152140519602, 12.425494079133493, 2.2535681260804887, 93.43059892137383,\n",
        "36.02323008849557, 1.8814665390815597, 1476.2334801762115, 57.076203671631454, 198.2465834818776, 15.867806841046278,\n",
        "52.084058888712995, 132.598406374502, 98.15198107628622]\n",
        "\n",
        "pos_weights = torch.FloatTensor(pos_weights).cuda()\n",
        "criterion = nn.BCEWithLogitsLoss(pos_weight=pos_weights)\n",
        "\n",
        "trainer.compile(lr, criterion, scheduler=True)\n",
        "\n",
        "trainer.train(epochs, batchSize)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 225,
          "referenced_widgets": [
            "b1d08d5abcf8498e84382694767f13b1",
            "f2b619c707e44efba4545171adca3aa8",
            "b286a69962b7409695423119afeef210",
            "e5e23a253ef44204b7a8bb87c9e0bd03",
            "8c0b3ff7fe934806a86378132e8645e6",
            "a151833ff090442eab9ac5dc3385ed4d",
            "072978a6bcc14085957ac85ff0b23f75",
            "35107212a856434aa7c178de06c05244",
            "5158413678aa4b4daf1547930418316e",
            "79b29cd430604617966bafd88d41aeee",
            "08e3220a6c534a6abb419fe8eea2b926"
          ]
        },
        "id": "PDsPZJTGA0we",
        "outputId": "4fe356bf-49c0-4c14-ab1c-9ab1d0d77d61"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "178730\n",
            "No. of images:\n",
            "\t|--Training: 178730\n",
            "\t|--Validation: 44682\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/densenet121-a639ec97.pth\" to /root/.cache/torch/hub/checkpoints/densenet121-a639ec97.pth\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b1d08d5abcf8498e84382694767f13b1",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "  0%|          | 0.00/30.8M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "trainin 2\n",
            "Epoch 1\tBatch [1/44683]\t\tTraining Loss: 0.5720852613449097\n",
            "Epoch 1\tBatch [501/44683]\t\tTraining Loss: 0.31706425607085453\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "torch.cuda.empty_cache()"
      ],
      "metadata": {
        "id": "Dc--4xeWGh5K"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}