{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Densenet121_NIH.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNAmvKDypPN5oXxFofnbyMO",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sisifo3/P_T_3/blob/main/Densenet121_NIH.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xaIbkKPlzYGu",
        "outputId": "c6627fb2-1488-488a-b89a-5183b43f661e"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r1Xh6cpszmt1"
      },
      "source": [
        "!tar -xf /content/drive/MyDrive/NIH_Dataset_total/images_001.tar.gz\n",
        "!tar -xf /content/drive/MyDrive/NIH_Dataset_total/images_002.tar.gz\n",
        "!tar -xf /content/drive/MyDrive/NIH_Dataset_total/images_003.tar.gz\n",
        "!tar -xf /content/drive/MyDrive/NIH_Dataset_total/images_004.tar.gz\n",
        "!tar -xf /content/drive/MyDrive/NIH_Dataset_total/images_005.tar.gz\n",
        "!tar -xf /content/drive/MyDrive/NIH_Dataset_total/images_006.tar.gz\n",
        "\n",
        "\n",
        "#!tar -xf /content/drive/MyDrive/NIH_Dataset_total/images_007.tar.gz\n",
        "#!tar -xf /content/drive/MyDrive/NIH_Dataset_total/images_008.tar.gz\n",
        "#!tar -xf /content/drive/MyDrive/NIH_Dataset_total/images_009.tar.gz\n",
        "#!tar -xf /content/drive/MyDrive/NIH_Dataset_total/images_010.tar.gz\n",
        "#!tar -xf /content/drive/MyDrive/NIH_Dataset_total/images_011.tar.gz\n",
        "#!tar -xf /content/drive/MyDrive/NIH_Dataset_total/images_012.tar.gz"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nhDRPEwgzpmu"
      },
      "source": [
        "pkl_dir_path             = 'pickles'\n",
        "train_val_df_pkl_path    = 'train_val_df.pickle'\n",
        "test_df_pkl_path         = 'test_df.pickle'\n",
        "disease_classes_pkl_path = 'disease_classes.pickle'\n",
        "models_dir               = 'models'\n",
        "\n",
        "from torchvision import transforms\n",
        "normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                                 std=[0.229, 0.224, 0.225])\n",
        "\n",
        "# transforms.RandomHorizontalFlip() not used because some disease might be more likely to the present in a specific lung (lelf/rigth)\n",
        "transform = transforms.Compose([transforms.ToPILImage(), \n",
        "                    transforms.Resize(224),\n",
        "                    transforms.ToTensor(),\n",
        "                    normalize])"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 208
        },
        "id": "-okEVf5szqaQ",
        "outputId": "3ad7bfcb-43b5-4cbd-b984-e40381b89711"
      },
      "source": [
        "import glob, os, sys, pdb, time\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import cv2\n",
        "import pickle\n",
        "from torch.utils.data import Dataset\n",
        "from tqdm import tqdm\n",
        "import torch\n",
        "\n",
        "#import config \n",
        "\n",
        "def q(text = ''): # easy way to exiting the script. useful while debugging\n",
        "    print('> ', text)\n",
        "    sys.exit()\n",
        "\n",
        "class XRaysTrainDataset(Dataset):\n",
        "    def __init__(self, data_dir, transform = None):\n",
        "        self.data_dir = data_dir\n",
        "\n",
        "        self.transform = transform\n",
        "        # print('self.data_dir: ', self.data_dir)\n",
        "\n",
        "        # full dataframe including train_val and test set\n",
        "        self.df = self.get_df()\n",
        "        print('self.df.shape: {}'.format(self.df.shape))\n",
        "\n",
        "        self.make_pkl_dir(pkl_dir_path)\n",
        "\n",
        "        # get train_val_df\n",
        "        if not os.path.exists(os.path.join(pkl_dir_path, train_val_df_pkl_path)):\n",
        "\n",
        "            self.train_val_df = self.get_train_val_df()\n",
        "            print('\\nself.train_val_df.shape: {}'.format(self.train_val_df.shape))\n",
        "\n",
        "            # pickle dump the train_val_df\n",
        "            with open(os.path.join(pkl_dir_path, train_val_df_pkl_path), 'wb') as handle:\n",
        "                pickle.dump(self.train_val_df, handle, protocol = pickle.HIGHEST_PROTOCOL)\n",
        "            print('{}: dumped'.format(train_val_df_pkl_path))\n",
        "            \n",
        "        else:\n",
        "            # pickle load the train_val_df\n",
        "            with open(os.path.join(pkl_dir_path, train_val_df_pkl_path), 'rb') as handle:\n",
        "                self.train_val_df = pickle.load(handle)\n",
        "            print('\\n{}: loaded'.format(train_val_df_pkl_path))\n",
        "            print('self.train_val_df.shape: {}'.format(self.train_val_df.shape))\n",
        "\n",
        "        self.the_chosen, self.all_classes, self.all_classes_dict = self.choose_the_indices()\n",
        "    \n",
        "        if not os.path.exists(os.path.join(pkl_dir_path, disease_classes_pkl_path)):\n",
        "            # pickle dump the classes list\n",
        "            with open(os.path.join(pkl_dir_path, disease_classes_pkl_path), 'wb') as handle:\n",
        "                pickle.dump(self.all_classes, handle, protocol = pickle.HIGHEST_PROTOCOL)\n",
        "                print('\\n{}: dumped'.format(disease_classes_pkl_path))\n",
        "        else:\n",
        "            print('\\n{}: already exists'.format(disease_classes_pkl_path))\n",
        "\n",
        "        self.new_df = self.train_val_df.iloc[self.the_chosen, :] # this is the sampled train_val data\n",
        "        print('\\nself.all_classes_dict: {}'.format(self.all_classes_dict))\n",
        "            \n",
        "    def resample(self):\n",
        "        self.the_chosen, self.all_classes, self.all_classes_dict = self.choose_the_indices()\n",
        "        self.new_df = self.train_val_df.iloc[self.the_chosen, :]\n",
        "        print('\\nself.all_classes_dict: {}'.format(self.all_classes_dict))\n",
        "\n",
        "    def make_pkl_dir(self, pkl_dir_path):\n",
        "        if not os.path.exists(pkl_dir_path):\n",
        "            os.mkdir(pkl_dir_path)\n",
        "\n",
        "    def get_train_val_df(self):\n",
        "\n",
        "        # get the list of train_val data \n",
        "        train_val_list = self.get_train_val_list()\n",
        "\n",
        "        train_val_df = pd.DataFrame()\n",
        "        print('\\nbuilding train_val_df...')\n",
        "        for i in tqdm(range(self.df.shape[0])):\n",
        "            filename  = os.path.basename(self.df.iloc[i,0])\n",
        "            # print('filename: ', filename)\n",
        "            if filename in train_val_list:\n",
        "                train_val_df = train_val_df.append(self.df.iloc[i:i+1, :])\n",
        "\n",
        "        # print('train_val_df.shape: {}'.format(train_val_df.shape))\n",
        "\n",
        "        return train_val_df\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        row = self.new_df.iloc[index, :]\n",
        "\n",
        "        img = cv2.imread(row['image_links'])\n",
        "        labels = str.split(row['Finding Labels'], '|')\n",
        "        \n",
        "        target = torch.zeros(len(self.all_classes))\n",
        "        for lab in labels:\n",
        "            lab_idx = self.all_classes.index(lab)\n",
        "            target[lab_idx] = 1            \n",
        "    \n",
        "        if self.transform is not None:\n",
        "            img = self.transform(img)\n",
        "    \n",
        "        return img, target\n",
        "        \n",
        "    def choose_the_indices(self):\n",
        "        \n",
        "        max_examples_per_class = 10000 # its the maximum number of examples that would be sampled in the training set for any class\n",
        "        the_chosen = []\n",
        "        all_classes = {}\n",
        "        length = len(self.train_val_df)\n",
        "        # for i in tqdm(range(len(merged_df))):\n",
        "        print('\\nSampling the huuuge training dataset')\n",
        "        for i in tqdm(list(np.random.choice(range(length),length, replace = False))):\n",
        "            \n",
        "            temp = str.split(self.train_val_df.iloc[i, :]['Finding Labels'], '|')\n",
        "\n",
        "            # special case of ultra minority hernia. we will use all the images with 'Hernia' tagged in them.\n",
        "            if 'Hernia' in temp:\n",
        "                the_chosen.append(i)\n",
        "                for t in temp:\n",
        "                    if t not in all_classes:\n",
        "                        all_classes[t] = 1\n",
        "                    else:\n",
        "                        all_classes[t] += 1\n",
        "                continue\n",
        "\n",
        "            # choose if multiple labels\n",
        "            if len(temp) > 1:\n",
        "                bool_lis = [False]*len(temp)\n",
        "                # check if any label crosses the upper limit\n",
        "                for idx, t in enumerate(temp):\n",
        "                    if t in all_classes:\n",
        "                        if all_classes[t]< max_examples_per_class: # 500\n",
        "                            bool_lis[idx] = True\n",
        "                    else:\n",
        "                        bool_lis[idx] = True\n",
        "                # if all lables under upper limit, append\n",
        "                if sum(bool_lis) == len(temp):                    \n",
        "                    the_chosen.append(i)\n",
        "                    # maintain count\n",
        "                    for t in temp:\n",
        "                        if t not in all_classes:\n",
        "                            all_classes[t] = 1\n",
        "                        else:\n",
        "                            all_classes[t] += 1\n",
        "            else:        # these are single label images\n",
        "                for t in temp:\n",
        "                    if t not in all_classes:\n",
        "                        all_classes[t] = 1\n",
        "                    else:\n",
        "                        if all_classes[t] < max_examples_per_class: # 500\n",
        "                            all_classes[t] += 1\n",
        "                            the_chosen.append(i)\n",
        "\n",
        "        # print('len(all_classes): ', len(all_classes))\n",
        "        # print('all_classes: ', all_classes)\n",
        "        # print('len(the_chosen): ', len(the_chosen))\n",
        "        \n",
        "        '''\n",
        "        if len(the_chosen) != len(set(the_chosen)):\n",
        "            print('\\nGadbad !!!')\n",
        "            print('and the difference is: ', len(the_chosen) - len(set(the_chosen)))\n",
        "        else:\n",
        "            print('\\nGood')\n",
        "        '''\n",
        "\n",
        "        return the_chosen, sorted(list(all_classes)), all_classes\n",
        "    \n",
        "    def get_df(self):\n",
        "        csv_path = os.path.join('/content/drive/MyDrive/NIH_Dataset_total/Data_Entry_2017_v2020.csv')\n",
        "        print('\\n{} found: {}'.format(csv_path, os.path.exists(csv_path)))\n",
        "        \n",
        "        all_xray_df = pd.read_csv(csv_path)\n",
        "\n",
        "        df = pd.DataFrame()        \n",
        "        df['image_links'] = [x for x in glob.glob(os.path.join('/content/images/*.png'))]\n",
        "\n",
        "        df['Image Index'] = df['image_links'].apply(lambda x : x[len(x)-16:len(x)])\n",
        "        merged_df = df.merge(all_xray_df, how = 'inner', on = ['Image Index'])\n",
        "        merged_df = merged_df[['image_links','Finding Labels']]\n",
        "        return merged_df\n",
        "    \n",
        "    def get_train_val_list(self):\n",
        "        f = open(os.path.join('data', 'NIH Chest X-rays', '/content/drive/MyDrive/NIH_Dataset_total/train_val_list.txt'), 'r')\n",
        "        train_val_list = str.split(f.read(), '\\n')\n",
        "        return train_val_list\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.new_df)\n",
        "\n",
        "\n",
        "# prepare the test dataset\n",
        "class XRaysTestDataset(Dataset):\n",
        "    def __init__(self, data_dir, transform = None):\n",
        "        self.data_dir = data_dir\n",
        "        self.transform = transform\n",
        "        # print('self.data_dir: ', self.data_dir)\n",
        "\n",
        "        # full dataframe including train_val and test set\n",
        "        self.df = self.get_df()\n",
        "        print('\\nself.df.shape: {}'.format(self.df.shape))\n",
        "\n",
        "        self.make_pkl_dir(pkl_dir_path)\n",
        "\n",
        "        # loading the classes list\n",
        "        with open(os.path.join(pkl_dir_path, disease_classes_pkl_path), 'rb') as handle:\n",
        "            self.all_classes = pickle.load(handle)\n",
        "\n",
        "        # get test_df\n",
        "        if not os.path.exists(os.path.join(pkl_dir_path, test_df_pkl_path)):\n",
        "\n",
        "            self.test_df = self.get_test_df()\n",
        "            print('self.test_df.shape: ', self.test_df.shape)\n",
        "            \n",
        "            # pickle dump the test_df\n",
        "            with open(os.path.join(pkl_dir_path, test_df_pkl_path), 'wb') as handle:\n",
        "                pickle.dump(self.test_df, handle, protocol = pickle.HIGHEST_PROTOCOL)\n",
        "            print('\\n{}: dumped'.format(test_df_pkl_path))\n",
        "        else:\n",
        "            # pickle load the test_df\n",
        "            with open(os.path.join(pkl_dir_path, test_df_pkl_path), 'rb') as handle:\n",
        "                self.test_df = pickle.load(handle)\n",
        "            print('\\n{}: loaded'.format(test_df_pkl_path))\n",
        "            print('self.test_df.shape: {}'.format(self.test_df.shape))\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        row = self.test_df.iloc[index, :]\n",
        "        \n",
        "        img = cv2.imread(row['image_links'])\n",
        "        labels = str.split(row['Finding Labels'], '|')\n",
        "        \n",
        "        target = torch.zeros(len(self.all_classes))\n",
        "        for lab in labels:\n",
        "            lab_idx = self.all_classes.index(lab)\n",
        "            target[lab_idx] = 1            \n",
        "    \n",
        "        if self.transform is not None:\n",
        "            img = self.transform(img)\n",
        "    \n",
        "        return img, target\n",
        "\n",
        "    def make_pkl_dir(self, pkl_dir_path):\n",
        "        if not os.path.exists(pkl_dir_path):\n",
        "            os.mkdir(pkl_dir_path)\n",
        "\n",
        "    def get_df(self):\n",
        "        csv_path = os.path.join('/content/drive/MyDrive/NIH_Dataset_total/Data_Entry_2017_v2020.csv')\n",
        "        \n",
        "        all_xray_df = pd.read_csv(csv_path)\n",
        "\n",
        "        df = pd.DataFrame()        \n",
        "        df['image_links'] = [x for x in glob.glob(os.path.join('/content/images/*.png'))]\n",
        "\n",
        "        df['Image Index'] = df['image_links'].apply(lambda x : x[len(x)-16:len(x)])\n",
        "        merged_df = df.merge(all_xray_df, how = 'inner', on = ['Image Index'])\n",
        "        merged_df = merged_df[['image_links','Finding Labels']]\n",
        "        return merged_df\n",
        "\n",
        "    def get_test_df(self):\n",
        "\n",
        "        # get the list of test data \n",
        "        test_list = self.get_test_list()\n",
        "\n",
        "        test_df = pd.DataFrame()\n",
        "        print('\\nbuilding test_df...')\n",
        "        for i in tqdm(range(self.df.shape[0])):\n",
        "            filename  = os.path.basename(self.df.iloc[i,0])\n",
        "            # print('filename: ', filename)\n",
        "            if filename in test_list:\n",
        "                test_df = test_df.append(self.df.iloc[i:i+1, :])\n",
        "         \n",
        "        print('test_df.shape: ', test_df.shape)\n",
        "\n",
        "        return test_df\n",
        "\n",
        "    def get_test_list(self):\n",
        "        f = open( os.path.join('data', 'NIH Chest X-rays', '/content/drive/MyDrive/NIH_Dataset_total/test_list.txt'), 'r')\n",
        "        test_list = str.split(f.read(), '\\n')\n",
        "        return test_list\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.test_df)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "'''\n",
        "# prepare the test dataset\n",
        "import random\n",
        "class XRaysTestDataset2(Dataset):\n",
        "    def __init__(self, test_data_dir, transform = None):\n",
        "        self.test_data_dir = test_data_dir\n",
        "        self.transform = transform\n",
        "        self.data_list = self.get_data_list(self.test_data_dir)\n",
        "        \n",
        "        self.subset = self.data_list[:1000]\n",
        "    def __getitem__(self, index):\n",
        "        img_path = self.data_list[index]\n",
        "        img = cv2.imread(img_path)\n",
        "        \n",
        "        if self.transform is not None:\n",
        "            img = self.transform(img)\n",
        "            \n",
        "        return img_path\n",
        "    \n",
        "    def sample(self):\n",
        "        random.shuffle(self.data_list)\n",
        "        self.subset = self.data_list[:np.random.randint(500,700)]\n",
        "    def __len__(self):\n",
        "        return len(self.subset)\n",
        "        \n",
        "    def get_data_list(self, data_dir):\n",
        "        data_list = []\n",
        "        for path in glob.glob(data_dir + os.sep + '*'):\n",
        "            data_list.append(path)\n",
        "        return data_list\n",
        "'''"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"\\n# prepare the test dataset\\nimport random\\nclass XRaysTestDataset2(Dataset):\\n    def __init__(self, test_data_dir, transform = None):\\n        self.test_data_dir = test_data_dir\\n        self.transform = transform\\n        self.data_list = self.get_data_list(self.test_data_dir)\\n        \\n        self.subset = self.data_list[:1000]\\n    def __getitem__(self, index):\\n        img_path = self.data_list[index]\\n        img = cv2.imread(img_path)\\n        \\n        if self.transform is not None:\\n            img = self.transform(img)\\n            \\n        return img_path\\n    \\n    def sample(self):\\n        random.shuffle(self.data_list)\\n        self.subset = self.data_list[:np.random.randint(500,700)]\\n    def __len__(self):\\n        return len(self.subset)\\n        \\n    def get_data_list(self, data_dir):\\n        data_list = []\\n        for path in glob.glob(data_dir + os.sep + '*'):\\n            data_list.append(path)\\n        return data_list\\n\""
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 210
        },
        "id": "tsJ-VTlAz6Vc",
        "outputId": "dded2a00-a955-4a4c-f2a5-323df9c1424a"
      },
      "source": [
        "import matplotlib\n",
        "matplotlib.use('Agg')\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import sys, os, time, random, pdb\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch.nn.functional as F\n",
        "import torch\n",
        "import pickle\n",
        "import tqdm, pdb\n",
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "#import config\n",
        "\n",
        "def get_roc_auc_score(y_true, y_probs):\n",
        "    '''\n",
        "    Uses roc_auc_score function from sklearn.metrics to calculate the micro ROC AUC score for a given y_true and y_probs.\n",
        "    '''\n",
        "\n",
        "    with open(os.path.join(pkl_dir_path, disease_classes_pkl_path), 'rb') as handle:\n",
        "        all_classes = pickle.load(handle)\n",
        "    \n",
        "    NoFindingIndex = all_classes.index('No Finding')\n",
        "\n",
        "    if True:\n",
        "        print('\\nNoFindingIndex: ', NoFindingIndex)\n",
        "        print('y_true.shape, y_probs.shape ', y_true.shape, y_probs.shape)\n",
        "        GT_and_probs = {'y_true': y_true, 'y_probs': y_probs}\n",
        "        with open('GT_and_probs', 'wb') as handle:\n",
        "            pickle.dump(GT_and_probs, handle, protocol = pickle.HIGHEST_PROTOCOL)\n",
        "\n",
        "    class_roc_auc_list = []    \n",
        "    useful_classes_roc_auc_list = []\n",
        "    \n",
        "    for i in range(y_true.shape[1]):\n",
        "        class_roc_auc = roc_auc_score(y_true[:, i], y_probs[:, i])\n",
        "        class_roc_auc_list.append(class_roc_auc)\n",
        "        if i != NoFindingIndex:\n",
        "            useful_classes_roc_auc_list.append(class_roc_auc)\n",
        "    if True:\n",
        "        print('\\nclass_roc_auc_list: ', class_roc_auc_list)\n",
        "        print('\\nuseful_classes_roc_auc_list', useful_classes_roc_auc_list)\n",
        "\n",
        "    return np.mean(np.array(useful_classes_roc_auc_list))\n",
        "\n",
        "def make_plot(epoch_train_loss, epoch_val_loss, total_train_loss_list, total_val_loss_list, save_name):\n",
        "    '''\n",
        "    This function makes the following 4 different plots-\n",
        "    1. mean train loss VS number of epochs\n",
        "    2. mean val   loss VS number of epochs\n",
        "    3. batch train loss for all the training   batches VS number of batches\n",
        "    4. batch val   loss for all the validation batches VS number of batches\n",
        "    '''\n",
        "    fig = plt.figure(figsize=(16,16))\n",
        "    fig.suptitle('loss trends', fontsize=20)\n",
        "    ax1 = fig.add_subplot(221)\n",
        "    ax2 = fig.add_subplot(222)\n",
        "    ax3 = fig.add_subplot(223)\n",
        "    ax4 = fig.add_subplot(224)\n",
        "\n",
        "    ax1.title.set_text('epoch train loss VS #epochs')\n",
        "    ax1.set_xlabel('#epochs')\n",
        "    ax1.set_ylabel('epoch train loss')\n",
        "    ax1.plot(epoch_train_loss)\n",
        "\n",
        "    ax2.title.set_text('epoch val loss VS #epochs')\n",
        "    ax2.set_xlabel('#epochs')\n",
        "    ax2.set_ylabel('epoch val loss')\n",
        "    ax2.plot(epoch_val_loss)\n",
        "\n",
        "    ax3.title.set_text('batch train loss VS #batches')\n",
        "    ax3.set_xlabel('#batches')\n",
        "    ax3.set_ylabel('batch train loss')\n",
        "    ax3.plot(total_train_loss_list)\n",
        "\n",
        "    ax4.title.set_text('batch val loss VS #batches')\n",
        "    ax4.set_xlabel('#batches')\n",
        "    ax4.set_ylabel('batch val loss')\n",
        "    ax4.plot(total_val_loss_list)\n",
        "    \n",
        "    plt.savefig(os.path.join(models_dir,'losses_{}.png'.format(save_name)))\n",
        "\n",
        "def get_resampled_train_val_dataloaders(XRayTrain_dataset, transform, bs):\n",
        "    '''\n",
        "    Resamples the XRaysTrainDataset class object and returns a training and a validation dataloaders, by splitting the sampled dataset in 80-20 ratio.\n",
        "    '''\n",
        "    XRayTrain_dataset.resample()\n",
        "\n",
        "    train_percentage = 0.8\n",
        "    train_dataset, val_dataset = torch.utils.data.random_split(XRayTrain_dataset, [int(len(XRayTrain_dataset)*train_percentage), len(XRayTrain_dataset)-int(len(XRayTrain_dataset)*train_percentage)])\n",
        "\n",
        "    print('\\n-----Resampled Dataset Information-----')\n",
        "    print('num images in train_dataset   : {}'.format(len(train_dataset)))\n",
        "    print('num images in val_dataset     : {}'.format(len(val_dataset)))\n",
        "    print('---------------------------------------')\n",
        "\n",
        "    # make dataloaders\n",
        "    train_loader = torch.utils.data.DataLoader(train_dataset, batch_size = bs, shuffle = True)\n",
        "    val_loader   = torch.utils.data.DataLoader(val_dataset,   batch_size = bs, shuffle = not True)\n",
        "\n",
        "    print('\\n-----Resampled Batchloaders Information -----')\n",
        "    print('num batches in train_loader: {}'.format(len(train_loader)))\n",
        "    print('num batches in val_loader  : {}'.format(len(val_loader)))\n",
        "    print('---------------------------------------------\\n')\n",
        "\n",
        "    return train_loader, val_loader\n",
        "    \n",
        "def train_epoch(device, train_loader, model, loss_fn, optimizer, epochs_till_now, final_epoch, log_interval):\n",
        "    '''\n",
        "    Takes in the data from the 'train_loader', calculates the loss over it using the 'loss_fn' \n",
        "    and optimizes the 'model' using the 'optimizer'  \n",
        "    \n",
        "    Also prints the loss and the ROC AUC score for the batches, after every 'log_interval' batches. \n",
        "    '''\n",
        "    model.train()\n",
        "    \n",
        "    running_train_loss = 0\n",
        "    train_loss_list = []\n",
        "\n",
        "    start_time = time.time()\n",
        "    for batch_idx, (img, target) in enumerate(train_loader):\n",
        "        # print(type(img), img.shape) # , np.unique(img))\n",
        "\n",
        "        img = img.to(device)\n",
        "        target = target.to(device)\n",
        "        \n",
        "        optimizer.zero_grad()    \n",
        "        out = model(img)        \n",
        "        loss = loss_fn(out, target)\n",
        "        running_train_loss += loss.item()*img.shape[0]\n",
        "        train_loss_list.append(loss.item())\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        \n",
        "        if (batch_idx+1)%log_interval == 0:\n",
        "            # batch metric evaluation\n",
        "# #             out_detached = out.detach()\n",
        "# #             batch_roc_auc_score = get_roc_auc_score(target, out_detached.numpy())\n",
        "            # 'out' is a torch.Tensor and 'roc_auc_score' function first tries to convert it into a numpy array, but since 'out' has requires_grad = True, it throws an error\n",
        "            # RuntimeError: Can't call numpy() on Variable that requires grad. Use var.detach().numpy() instead. \n",
        "            # so we have to 'detach' the 'out' tensor and then convert it into a numpy array to avoid the error !  \n",
        "\n",
        "            batch_time = time.time() - start_time\n",
        "            m, s = divmod(batch_time, 60)\n",
        "            print('Train Loss for batch {}/{} @epoch{}/{}: {} in {} mins {} secs'.format(str(batch_idx+1).zfill(3), str(len(train_loader)).zfill(3), epochs_till_now, final_epoch, round(loss.item(), 5), int(m), round(s, 2)))\n",
        "        \n",
        "        start_time = time.time()\n",
        "            \n",
        "    return train_loss_list, running_train_loss/float(len(train_loader.dataset))\n",
        "\n",
        "def val_epoch(device, val_loader, model, loss_fn, epochs_till_now = None, final_epoch = None, log_interval = 1, test_only = False):\n",
        "    '''\n",
        "    It essentially takes in the val_loader/test_loader, the model and the loss function and evaluates\n",
        "    the loss and the ROC AUC score for all the data in the dataloader.\n",
        "    \n",
        "    It also prints the loss and the ROC AUC score for every 'log_interval'th batch, only when 'test_only' is False\n",
        "    '''\n",
        "    model.eval()\n",
        "\n",
        "    running_val_loss = 0\n",
        "    val_loss_list = []\n",
        "    val_loader_examples_num = len(val_loader.dataset)\n",
        "\n",
        "    probs = np.zeros((val_loader_examples_num, 15), dtype = np.float32)\n",
        "    gt    = np.zeros((val_loader_examples_num, 15), dtype = np.float32)\n",
        "    k=0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        batch_start_time = time.time()    \n",
        "        for batch_idx, (img, target) in enumerate(val_loader):\n",
        "            if test_only:\n",
        "                per = ((batch_idx+1)/len(val_loader))*100\n",
        "                a_, b_ = divmod(per, 1)\n",
        "                print(f'{str(batch_idx+1).zfill(len(str(len(val_loader))))}/{str(len(val_loader)).zfill(len(str(len(val_loader))))} ({str(int(a_)).zfill(2)}.{str(int(100*b_)).zfill(2)} %)', end = '\\r')\n",
        "    #         print(type(img), img.shape) # , np.unique(img))\n",
        "\n",
        "            img = img.to(device)\n",
        "            target = target.to(device)    \n",
        "    \n",
        "            out = model(img)        \n",
        "            loss = loss_fn(out, target)    \n",
        "            running_val_loss += loss.item()*img.shape[0]\n",
        "            val_loss_list.append(loss.item())\n",
        "\n",
        "            # storing model predictions for metric evaluat`ion \n",
        "            probs[k: k + out.shape[0], :] = out.cpu()\n",
        "            gt[   k: k + out.shape[0], :] = target.cpu()\n",
        "            k += out.shape[0]\n",
        "\n",
        "            if ((batch_idx+1)%log_interval == 0) and (not test_only): # only when ((batch_idx + 1) is divisible by log_interval) and (when test_only = False)\n",
        "                # batch metric evaluation\n",
        "#                 batch_roc_auc_score = get_roc_auc_score(target, out)\n",
        "\n",
        "                batch_time = time.time() - batch_start_time\n",
        "                m, s = divmod(batch_time, 60)\n",
        "                print('Val Loss   for batch {}/{} @epoch{}/{}: {} in {} mins {} secs'.format(str(batch_idx+1).zfill(3), str(len(val_loader)).zfill(3), epochs_till_now, final_epoch, round(loss.item(), 5), int(m), round(s, 2)))\n",
        "            \n",
        "            batch_start_time = time.time()    \n",
        "            \n",
        "    # metric scenes\n",
        "    roc_auc = get_roc_auc_score(gt, probs)\n",
        "\n",
        "    return val_loss_list, running_val_loss/float(len(val_loader.dataset)), roc_auc\n",
        "\n",
        "def fit(device, XRayTrain_dataset, train_loader, val_loader, test_loader, model,\n",
        "                                         loss_fn, optimizer, losses_dict,\n",
        "                                         epochs_till_now, epochs, \n",
        "                                         log_interval, save_interval, \n",
        "                                         lr, bs, stage, test_only = False):\n",
        "    '''\n",
        "    Trains or Tests the 'model' on the given 'train_loader', 'val_loader', 'test_loader' for 'epochs' number of epochs.\n",
        "    If training ('test_only' = False), it saves the optimized 'model' and  the loss plots ,after every 'save_interval'th epoch.\n",
        "    '''\n",
        "    epoch_train_loss, epoch_val_loss, total_train_loss_list, total_val_loss_list = losses_dict['epoch_train_loss'], losses_dict['epoch_val_loss'], losses_dict['total_train_loss_list'], losses_dict['total_val_loss_list']\n",
        "\n",
        "    final_epoch = epochs_till_now + epochs\n",
        "\n",
        "    if test_only:\n",
        "        print('\\n======= Testing... =======\\n')\n",
        "        test_start_time = time.time()\n",
        "        test_loss, mean_running_test_loss, test_roc_auc = val_epoch(device, test_loader, model, loss_fn, log_interval, test_only = test_only)\n",
        "        total_test_time = time.time() - test_start_time\n",
        "        m, s = divmod(total_test_time, 60)\n",
        "        print('test_roc_auc: {} in {} mins {} secs'.format(test_roc_auc, int(m), int(s)))\n",
        "        sys.exit()\n",
        "\n",
        "    starting_epoch  = epochs_till_now\n",
        "    print('\\n======= Training after epoch #{}... =======\\n'.format(epochs_till_now))\n",
        "\n",
        "    # epoch_train_loss = []\n",
        "    # epoch_val_loss = []\n",
        "    \n",
        "    # total_train_loss_list = []\n",
        "    # total_val_loss_list = []\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "\n",
        "        if starting_epoch != epochs_till_now:\n",
        "            # resample the train_loader and val_loader\n",
        "            train_loader, val_loader = get_resampled_train_val_dataloaders(XRayTrain_dataset, config.transform, bs = bs)\n",
        "\n",
        "        epochs_till_now += 1\n",
        "        print('============ EPOCH {}/{} ============'.format(epochs_till_now, final_epoch))\n",
        "        epoch_start_time = time.time()\n",
        "        \n",
        "        print('TRAINING')\n",
        "        train_loss, mean_running_train_loss  =  train_epoch(device, train_loader, model, loss_fn, optimizer, epochs_till_now, final_epoch, log_interval)\n",
        "        print('VALIDATION')\n",
        "        val_loss, mean_running_val_loss, roc_auc     =  val_epoch(device, val_loader, model, loss_fn, epochs_till_now, final_epoch, log_interval)\n",
        "        \n",
        "        epoch_train_loss.append(mean_running_train_loss)\n",
        "        epoch_val_loss.append(mean_running_val_loss)\n",
        "\n",
        "        total_train_loss_list.extend(train_loss)\n",
        "        total_val_loss_list.extend(val_loss)\n",
        "\n",
        "        save_name = 'stage{}_{}_{}'.format(stage, str.split(str(lr), '.')[-1], str(epochs_till_now).zfill(2))\n",
        "\n",
        "        # the follwoing piece of codw needs to be worked on !!! LATEST DEVELOPMENT TILL HERE\n",
        "        if ((epoch+1)%save_interval == 0) or test_only:\n",
        "            save_path = os.path.join(models_dir, '{}.pth'.format(save_name))\n",
        "            \n",
        "            torch.save({\n",
        "            'epochs': epochs_till_now,\n",
        "            'model': model, # it saves the whole model\n",
        "            'losses_dict': {'epoch_train_loss': epoch_train_loss, 'epoch_val_loss': epoch_val_loss, 'total_train_loss_list': total_train_loss_list, 'total_val_loss_list': total_val_loss_list}\n",
        "            }, save_path)\n",
        "            \n",
        "            print('\\ncheckpoint {} saved'.format(save_path))\n",
        "\n",
        "            make_plot(epoch_train_loss, epoch_val_loss, total_train_loss_list, total_val_loss_list, save_name)\n",
        "            print('loss plots saved !!!')\n",
        "\n",
        "        print('\\nTRAIN LOSS : {}'.format(mean_running_train_loss))\n",
        "        print('VAL   LOSS : {}'.format(mean_running_val_loss))\n",
        "        print('VAL ROC_AUC: {}'.format(roc_auc))\n",
        "\n",
        "        total_epoch_time = time.time() - epoch_start_time\n",
        "        m, s = divmod(total_epoch_time, 60)\n",
        "        h, m = divmod(m, 60)\n",
        "        print('\\nEpoch {}/{} took {} h {} m'.format(epochs_till_now, final_epoch, int(h), int(m)))\n",
        "\n",
        "\n",
        "\n",
        "'''   \n",
        "def pred_n_write(test_loader, model, save_name):\n",
        "    res = np.zeros((3000, 15), dtype = np.float32)\n",
        "    k=0\n",
        "    for batch_idx, img in tqdm.tqdm(enumerate(test_loader)):\n",
        "        model.eval()\n",
        "        with torch.no_grad():\n",
        "            pred = torch.sigmoid(model(img))\n",
        "            # print(k)\n",
        "            res[k: k + pred.shape[0], :] = pred\n",
        "            k += pred.shape[0]\n",
        "            \n",
        "    # write csv\n",
        "    print('populating the csv')\n",
        "    submit = pd.DataFrame()\n",
        "    submit['ImageID'] = [str.split(i, os.sep)[-1] for i in test_loader.dataset.data_list]\n",
        "    with open('disease_classes.pickle', 'rb') as handle:\n",
        "        disease_classes = pickle.load(handle)\n",
        "    \n",
        "    for idx, col in enumerate(disease_classes):\n",
        "        if col == 'Hernia':\n",
        "            submit['Hern'] = res[:, idx]\n",
        "        elif col == 'Pleural_Thickening':\n",
        "            submit['Pleural_thickening'] = res[:, idx]\n",
        "        elif col == 'No Finding':\n",
        "            submit['No_findings'] = res[:, idx]\n",
        "        else:\n",
        "            submit[col] = res[:, idx]\n",
        "    rand_num = str(random.randint(1000, 9999))\n",
        "    csv_name = '{}___{}.csv'.format(save_name, rand_num)\n",
        "    submit.to_csv('res/' + csv_name, index = False)\n",
        "    print('{} saved !'.format(csv_name))\n",
        "'''"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"   \\ndef pred_n_write(test_loader, model, save_name):\\n    res = np.zeros((3000, 15), dtype = np.float32)\\n    k=0\\n    for batch_idx, img in tqdm.tqdm(enumerate(test_loader)):\\n        model.eval()\\n        with torch.no_grad():\\n            pred = torch.sigmoid(model(img))\\n            # print(k)\\n            res[k: k + pred.shape[0], :] = pred\\n            k += pred.shape[0]\\n            \\n    # write csv\\n    print('populating the csv')\\n    submit = pd.DataFrame()\\n    submit['ImageID'] = [str.split(i, os.sep)[-1] for i in test_loader.dataset.data_list]\\n    with open('disease_classes.pickle', 'rb') as handle:\\n        disease_classes = pickle.load(handle)\\n    \\n    for idx, col in enumerate(disease_classes):\\n        if col == 'Hernia':\\n            submit['Hern'] = res[:, idx]\\n        elif col == 'Pleural_Thickening':\\n            submit['Pleural_thickening'] = res[:, idx]\\n        elif col == 'No Finding':\\n            submit['No_findings'] = res[:, idx]\\n        else:\\n            submit[col] = res[:, idx]\\n    rand_num = str(random.randint(1000, 9999))\\n    csv_name = '{}___{}.csv'.format(save_name, rand_num)\\n    submit.to_csv('res/' + csv_name, index = False)\\n    print('{} saved !'.format(csv_name))\\n\""
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_75qvD5fz9q4"
      },
      "source": [
        "###################Temporal model densenet121##################\n",
        "#######################Using in CheXpert######################\n",
        "\n",
        "import torch\n",
        "import  torchvision\n",
        "import torch.nn as nn\n",
        "from torchsummary import summary\n",
        "\n",
        "class DenseNet121(nn.Module):\n",
        "    \n",
        "    def __init__(self, out_size, test=False):\n",
        "        super(DenseNet121, self).__init__()\n",
        "        self.test = test\n",
        "        self.densenet121 = torchvision.models.densenet121(pretrained=True)\n",
        "        num_ftrs = self.densenet121.classifier.in_features\n",
        "        self.densenet121.classifier = nn.Sequential(\n",
        "            nn.Linear(num_ftrs, num_ftrs),\n",
        "            nn.BatchNorm1d(num_ftrs),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout(0.5),\n",
        "            nn.Linear(num_ftrs, num_ftrs//2),\n",
        "            nn.BatchNorm1d(num_ftrs//2),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout(0.25),\n",
        "            nn.Linear(num_ftrs//2, out_size),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.densenet121(x)\n",
        "\n",
        "        if self.test:\n",
        "            return torch.sigmoid(x)\n",
        "        else:\n",
        "            return x"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LqiuUhs3z-kC",
        "outputId": "777fe321-0392-4c13-f7c0-1e4de7e0466c"
      },
      "source": [
        "import torch, sys, os, pdb\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class FocalLoss(nn.Module):\n",
        "    \n",
        "    def __init__(self, device, gamma = 1.0):\n",
        "        super(FocalLoss, self).__init__()\n",
        "        self.device = device\n",
        "        self.gamma = torch.tensor(gamma, dtype = torch.float32).to(device)\n",
        "        self.eps = 1e-6\n",
        "        \n",
        "#         self.BCE_loss = nn.BCEWithLogitsLoss(reduction='none').to(device)\n",
        "        \n",
        "    def forward(self, input, target):\n",
        "        \n",
        "        BCE_loss = F.binary_cross_entropy_with_logits(input, target, reduction='none').to(self.device)\n",
        "#         BCE_loss = self.BCE_loss(input, target)\n",
        "        pt = torch.exp(-BCE_loss) # prevents nans when probability 0\n",
        "        F_loss =  (1-pt)**self.gamma * BCE_loss\n",
        "        \n",
        "        return F_loss.mean() \n",
        "\n",
        "    # def forward(self, input, target):\n",
        "\n",
        "    #     # input are not the probabilities, they are just the cnn out vector\n",
        "    #     # input and target shape: (bs, n_classes)\n",
        "    #     # sigmoid\n",
        "    #     probs = torch.sigmoid(input)\n",
        "    #     log_probs = -torch.log(probs)\n",
        "\n",
        "    #     focal_loss = torch.sum(   torch.pow(1-probs + self.eps, self.gamma).mul(log_probs).mul(target)   , dim=1)\n",
        "    #     # bce_loss = torch.sum(log_probs.mul(target), dim = 1)\n",
        "        \n",
        "    #     return focal_loss.mean() #, bce_loss\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    inp = torch.tensor([[1., 0.95], \n",
        "                        [.9, 0.3], \n",
        "                        [0.6, 0.4]], requires_grad = True)\n",
        "    target = torch.tensor([[1., 1], \n",
        "                        [1, 0], \n",
        "                        [0, 0]])\n",
        "\n",
        "    print('inp\\n',inp, '\\n')\n",
        "    print('target\\n',target, '\\n')\n",
        "\n",
        "    print('inp.requires_grad:', inp.requires_grad, inp.shape)\n",
        "    print('target.requires_grad:', target.requires_grad, target.shape)\n",
        "\n",
        "\n",
        "    #loss = FocalLoss(device,gamma = 2)\n",
        "\n",
        "    #focal_loss, bce_loss = loss(inp ,target)\n",
        "    #print('\\nbce_loss',bce_loss, '\\n')\n",
        "    #print('\\nfocal_loss',focal_loss, '\\n')"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "inp\n",
            " tensor([[1.0000, 0.9500],\n",
            "        [0.9000, 0.3000],\n",
            "        [0.6000, 0.4000]], requires_grad=True) \n",
            "\n",
            "target\n",
            " tensor([[1., 1.],\n",
            "        [1., 0.],\n",
            "        [0., 0.]]) \n",
            "\n",
            "inp.requires_grad: True torch.Size([3, 2])\n",
            "target.requires_grad: False torch.Size([3, 2])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9aB6IqfK0HFt",
        "outputId": "0fe2d0e8-aaac-4041-b366-c829a576ef2e"
      },
      "source": [
        "import argparse\n",
        "import os, pdb, sys, glob, time\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "import cv2\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision.models as models \n",
        "\n",
        "# import custom dataset classes\n",
        "#from datasets import XRaysTrainDataset  \n",
        "#from datasets import XRaysTestDataset\n",
        "\n",
        "# import neccesary libraries for defining the optimizers\n",
        "import torch.optim as optim\n",
        "\n",
        "#from trainer import fit\n",
        "#import config\n",
        "\n",
        "def q(text = ''): # easy way to exiting the script. useful while debugging\n",
        "    print('> ', text)\n",
        "    sys.exit()\n",
        "\n",
        "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
        "print(f'\\ndevice: {device}')\n",
        "    \n",
        "parser = argparse.ArgumentParser(description='Following are the arguments that can be passed form the terminal itself ! Cool huh ? :D')\n",
        "parser.add_argument('--data_path', type = str, default = 'NIH Chest X-rays', help = 'This is the path of the training data')\n",
        "parser.add_argument('--bs', type = int, default = 16, help = 'batch size')\n",
        "parser.add_argument('--lr', type = float, default = 0.001, help = 'Learning Rate for the optimizer')\n",
        "parser.add_argument('--stage', type = int, default = 1, help = 'Stage, it decides which layers of the Neural Net to train')\n",
        "parser.add_argument('--loss_func', type = str, default = 'FocalLoss', choices = {'BCE', 'FocalLoss'}, help = 'loss function')\n",
        "parser.add_argument('-r','--resume', action = 'store_false') # args.resume will return True if -r or --resume is used in the terminal\n",
        "parser.add_argument('--ckpt', type = str, default = '/content/models/stage1_001_01.pth',help = 'Path of the ckeckpoint that you wnat to load')\n",
        "parser.add_argument('-t','--test', action = 'store_true')   # args.test   will return True if -t or --test   is used in the terminal\n",
        "parser.add_argument('-f')\n",
        "args = parser.parse_args()\n",
        "\n",
        "if args.resume and args.test: # what if --test is not defiend at all ? test case hai ye ek\n",
        "    q('The flow of this code has been designed either to train the model or to test it.\\nPlease choose either --resume or --test')\n",
        "\n",
        "stage = args.stage\n",
        "if not args.resume:\n",
        "    print(f'\\nOverwriting stage to 1, as the model training is being done from scratch')\n",
        "    stage = 1\n",
        "    \n",
        "if args.test:\n",
        "    print('TESTING THE MODEL')\n",
        "else:\n",
        "    if args.resume:\n",
        "        print('RESUMING THE MODEL TRAINING')\n",
        "    else:\n",
        "        print('TRAINING THE MODEL FROM SCRATCH')\n",
        "\n",
        "script_start_time = time.time() # tells the total run time of this script\n",
        "\n",
        "# mention the path of the data\n",
        "data_dir = os.path.join('data',args.data_path) # Data_Entry_2017.csv should be present in the mentioned path\n",
        "\n",
        "# define a function to count the total number of trainable parameters\n",
        "def count_parameters(model): \n",
        "    num_parameters = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "    return num_parameters/1e6 # in terms of millions\n",
        "\n",
        "# make the datasets\n",
        "XRayTrain_dataset = XRaysTrainDataset(data_dir, transform = transform)\n",
        "train_percentage = 0.8\n",
        "train_dataset, val_dataset = torch.utils.data.random_split(XRayTrain_dataset, [int(len(XRayTrain_dataset)*train_percentage), len(XRayTrain_dataset)-int(len(XRayTrain_dataset)*train_percentage)])\n",
        "\n",
        "XRayTest_dataset = XRaysTestDataset(data_dir, transform = transform)\n",
        "\n",
        "print('\\n-----Initial Dataset Information-----')\n",
        "print('num images in train_dataset   : {}'.format(len(train_dataset)))\n",
        "print('num images in val_dataset     : {}'.format(len(val_dataset)))\n",
        "print('num images in XRayTest_dataset: {}'.format(len(XRayTest_dataset)))\n",
        "print('-------------------------------------')\n",
        "\n",
        "# make the dataloaders\n",
        "batch_size = args.bs # 128 by default\n",
        "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size = batch_size, shuffle = True)\n",
        "val_loader = torch.utils.data.DataLoader(val_dataset, batch_size = batch_size, shuffle = not True)\n",
        "test_loader = torch.utils.data.DataLoader(XRayTest_dataset, batch_size = batch_size, shuffle = not True)\n",
        "\n",
        "print('\\n-----Initial Batchloaders Information -----')\n",
        "print('num batches in train_loader: {}'.format(len(train_loader)))\n",
        "print('num batches in val_loader  : {}'.format(len(val_loader)))\n",
        "print('num batches in test_loader : {}'.format(len(test_loader)))\n",
        "print('-------------------------------------------')\n",
        "\n",
        "# sanity check\n",
        "if len(XRayTrain_dataset.all_classes) != 15: # 15 is the unique number of diseases in this dataset\n",
        "    q('\\nnumber of classes not equal to 15 !')\n",
        "\n",
        "a,b = train_dataset[0]\n",
        "print('\\nwe are working with \\nImages shape: {} and \\nTarget shape: {}'.format( a.shape, b.shape))\n",
        "\n",
        "# make models directory, where the models and the loss plots will be saved\n",
        "if not os.path.exists(models_dir):\n",
        "    os.mkdir(models_dir)\n",
        "\n",
        "# define the loss function\n",
        "if args.loss_func == 'FocalLoss': # by default\n",
        "    #from losses import FocalLoss\n",
        "    loss_fn = FocalLoss(device = device, gamma = 2.).to(device)\n",
        "elif args.loss_func == 'BCE':\n",
        "    loss_fn = nn.BCEWithLogitsLoss().to(device)\n",
        "\n",
        "# define the learning rate\n",
        "lr = args.lr\n",
        "\n",
        "if not args.test: # training\n",
        "\n",
        "    # initialize the model if not args.resume\n",
        "    if not args.resume:\n",
        "        print('\\ntraining from scratch')\n",
        "        #########################################3\n",
        "        ######################\n",
        "        # import pretrained model\n",
        "        ####model = models.resnet50(pretrained=True) # pretrained = False bydefault\n",
        "        # change the last linear layer\n",
        "        ####num_ftrs = model.fc.in_features\n",
        "        ####model.fc = nn.Linear(num_ftrs, len(XRayTrain_dataset.all_classes)) # 15 output classes \n",
        "        num_classes = (len(XRayTrain_dataset.all_classes))\n",
        "        model = DenseNet121(num_classes)\n",
        "        model = torch.nn.DataParallel(model)\n",
        "        model.cuda()\n",
        "\n",
        "        #checkpoint = '/content/drive/MyDrive/NIH_Dataset_total/weights_Densenet121/weightsDensenet_121_v13'  \n",
        "        #checkpoint = torch.load(checkpoint)\n",
        "        #model.load_state_dict(checkpoint['model_state_dict'])\n",
        "        \n",
        "        #############################3\n",
        "        ##############################\n",
        "\n",
        "        model.to(device)\n",
        "        \n",
        "        print('----- STAGE 1 -----') # only training 'layer2', 'layer3', 'layer4' and 'fc'\n",
        "        for name, param in model.named_parameters(): # all requires_grad by default, are True initially\n",
        "            # print('{}: {}'.format(name, param.requires_grad)) # this shows True for all the parameters  \n",
        "            if ('layer2' in name) or ('layer3' in name) or ('layer4' in name) or ('fc' in name):\n",
        "                param.requires_grad = True \n",
        "            else:\n",
        "                param.requires_grad = False\n",
        "\n",
        "        # since we are not resuming the training of the model\n",
        "        epochs_till_now = 0\n",
        "\n",
        "        # making empty lists to collect all the losses\n",
        "        losses_dict = {'epoch_train_loss': [], 'epoch_val_loss': [], 'total_train_loss_list': [], 'total_val_loss_list': []}\n",
        "\n",
        "    else:\n",
        "        if args.ckpt == None:\n",
        "            q('ERROR: Please select a valid checkpoint to resume from')\n",
        "            \n",
        "        print('\\nckpt loaded: {}'.format(args.ckpt))\n",
        "        ckpt = torch.load(os.path.join(models_dir, args.ckpt)) \n",
        "\n",
        "        # since we are resuming the training of the model\n",
        "        epochs_till_now = ckpt['epochs']\n",
        "        model = ckpt['model']\n",
        "        model.to(device)\n",
        "        \n",
        "        # loading previous loss lists to collect future losses\n",
        "        losses_dict = ckpt['losses_dict']\n",
        "\n",
        "    # printing some hyperparameters\n",
        "    print('\\n> loss_fn: {}'.format(loss_fn))\n",
        "    print('> epochs_till_now: {}'.format(epochs_till_now))\n",
        "    print('> batch_size: {}'.format(batch_size))\n",
        "    print('> stage: {}'.format(stage))\n",
        "    print('> lr: {}'.format(lr))\n",
        "\n",
        "else: # testing\n",
        "    if args.ckpt == None:\n",
        "        q('ERROR: Please select a checkpoint to load the testing model from')\n",
        "        \n",
        "    print('\\ncheckpoint loaded: {}'.format(args.ckpt))\n",
        "    ckpt = torch.load(os.path.join(models_dir, args.ckpt)) \n",
        "\n",
        "    # since we are resuming the training of the model\n",
        "    epochs_till_now = ckpt['epochs']\n",
        "    model = ckpt['model']\n",
        "    \n",
        "    # loading previous loss lists to collect future losses\n",
        "    losses_dict = ckpt['losses_dict']\n",
        "\n",
        "# make changes(freezing/unfreezing the model's layers) in the following, for training the model for different stages \n",
        "if (not args.test) and (args.resume):\n",
        "\n",
        "    if stage == 1:\n",
        "\n",
        "        print('\\n----- STAGE 1 -----') # only training 'layer2', 'layer3', 'layer4' and 'fc'\n",
        "        for name, param in model.named_parameters(): # all requires_grad by default, are True initially\n",
        "            # print('{}: {}'.format(name, param.requires_grad)) # this shows True for all the parameters  \n",
        "            if ('layer2' in name) or ('layer3' in name) or ('layer4' in name) or ('fc' in name):\n",
        "                param.requires_grad = True \n",
        "            else:\n",
        "                param.requires_grad = False\n",
        "\n",
        "    elif stage == 2:\n",
        "\n",
        "        print('\\n----- STAGE 2 -----') # only training 'layer3', 'layer4' and 'fc'\n",
        "        for name, param in model.named_parameters(): \n",
        "            # print('{}: {}'.format(name, param.requires_grad)) # this shows True for all the parameters  \n",
        "            if ('layer3' in name) or ('layer4' in name) or ('fc' in name):\n",
        "                param.requires_grad = True \n",
        "            else:\n",
        "                param.requires_grad = False\n",
        "\n",
        "    elif stage == 3:\n",
        "\n",
        "        print('\\n----- STAGE 3 -----') # only training  'layer4' and 'fc'\n",
        "        for name, param in model.named_parameters(): \n",
        "            # print('{}: {}'.format(name, param.requires_grad)) # this shows True for all the parameters  \n",
        "            if ('layer4' in name) or ('fc' in name):\n",
        "                param.requires_grad = True \n",
        "            else:\n",
        "                param.requires_grad = False\n",
        "\n",
        "    elif stage == 4:\n",
        "\n",
        "        print('\\n----- STAGE 4 -----') # only training 'fc'\n",
        "        for name, param in model.named_parameters(): \n",
        "            # print('{}: {}'.format(name, param.requires_grad)) # this shows True for all the parameters  \n",
        "            if ('fc' in name):\n",
        "                param.requires_grad = True \n",
        "            else:\n",
        "                param.requires_grad = False\n",
        "\n",
        "\n",
        "if not args.test:\n",
        "    # checking the layers which are going to be trained (irrespective of args.resume)\n",
        "    trainable_layers = []\n",
        "    for name, param in model.named_parameters():\n",
        "        if param.requires_grad == True:\n",
        "            layer_name = str.split(name, '.')[0]\n",
        "            if layer_name not in trainable_layers: \n",
        "                trainable_layers.append(layer_name)\n",
        "    print('\\nfollowing are the trainable layers...')\n",
        "    print(trainable_layers)\n",
        "\n",
        "    print('\\nwe have {} Million trainable parameters here in the {} model'.format(count_parameters(model), model.__class__.__name__))\n",
        "\n",
        "optimizer = optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr = lr)\n",
        "\n",
        "# make changes in the parameters of the following 'fit' function\n",
        "fit(device, XRayTrain_dataset, train_loader, val_loader,    \n",
        "                                        test_loader, model, loss_fn, \n",
        "                                        optimizer, losses_dict,\n",
        "                                        epochs_till_now = epochs_till_now, epochs = 1,\n",
        "                                        log_interval = 25, save_interval = 1,\n",
        "                                        lr = lr, bs = batch_size, stage = stage,\n",
        "                                        test_only = args.test)\n",
        "\n",
        "script_time = time.time() - script_start_time\n",
        "m, s = divmod(script_time, 60)\n",
        "h, m = divmod(m, 60)\n",
        "print('{} h {}m laga poore script me !'.format(int(h), int(m)))\n",
        "\n",
        "# ''' \n",
        "# This is how the model is trained...\n",
        "# ##### STAGE 1 ##### FocalLoss lr = 1e-5\n",
        "# training layers = layer2, layer3, layer4, fc \n",
        "# epochs = 2\n",
        "# ##### STAGE 2 ##### FocalLoss lr = 3e-4\n",
        "# training layers = layer3, layer4, fc \n",
        "# epochs = 5\n",
        "# ##### STAGE 3 ##### FocalLoss lr = 7e-4\n",
        "# training layers = layer4, fc \n",
        "# epochs = 4\n",
        "# ##### STAGE 4 ##### FocalLoss lr = 1e-3\n",
        "# training layers = fc \n",
        "# epochs = 3\n",
        "# '''"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "device: cuda\n",
            "RESUMING THE MODEL TRAINING\n",
            "\n",
            "/content/drive/MyDrive/NIH_Dataset_total/Data_Entry_2017_v2020.csv found: True\n",
            "self.df.shape: (54999, 2)\n",
            "\n",
            "train_val_df.pickle: loaded\n",
            "self.train_val_df.shape: (44597, 2)\n",
            "\n",
            "Sampling the huuuge training dataset\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 44597/44597 [00:07<00:00, 5952.16it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "disease_classes.pickle: already exists\n",
            "\n",
            "self.all_classes_dict: {'Consolidation': 1455, 'Infiltration': 5800, 'Mass': 1743, 'No Finding': 10000, 'Atelectasis': 4082, 'Effusion': 4166, 'Emphysema': 762, 'Pneumothorax': 1282, 'Pneumonia': 421, 'Cardiomegaly': 863, 'Pleural_Thickening': 1089, 'Nodule': 2198, 'Edema': 642, 'Fibrosis': 792, 'Hernia': 79}\n",
            "\n",
            "self.df.shape: (54999, 2)\n",
            "\n",
            "test_df.pickle: loaded\n",
            "self.test_df.shape: (10402, 2)\n",
            "\n",
            "-----Initial Dataset Information-----\n",
            "num images in train_dataset   : 21716\n",
            "num images in val_dataset     : 5430\n",
            "num images in XRayTest_dataset: 10402\n",
            "-------------------------------------\n",
            "\n",
            "-----Initial Batchloaders Information -----\n",
            "num batches in train_loader: 1358\n",
            "num batches in val_loader  : 340\n",
            "num batches in test_loader : 651\n",
            "-------------------------------------------\n",
            "\n",
            "we are working with \n",
            "Images shape: torch.Size([3, 224, 224]) and \n",
            "Target shape: torch.Size([15])\n",
            "\n",
            "ckpt loaded: /content/models/stage1_001_01.pth\n",
            "\n",
            "> loss_fn: FocalLoss()\n",
            "> epochs_till_now: 1\n",
            "> batch_size: 16\n",
            "> stage: 1\n",
            "> lr: 0.001\n",
            "\n",
            "----- STAGE 1 -----\n",
            "\n",
            "following are the trainable layers...\n",
            "['module']\n",
            "\n",
            "we have 1.70848 Million trainable parameters here in the DataParallel model\n",
            "\n",
            "======= Training after epoch #1... =======\n",
            "\n",
            "============ EPOCH 2/2 ============\n",
            "TRAINING\n",
            "Train Loss for batch 025/1358 @epoch2/2: 0.20108 in 0 mins 0.62 secs\n",
            "Train Loss for batch 050/1358 @epoch2/2: 0.21479 in 0 mins 0.62 secs\n",
            "Train Loss for batch 075/1358 @epoch2/2: 0.21276 in 0 mins 0.63 secs\n",
            "Train Loss for batch 100/1358 @epoch2/2: 0.19836 in 0 mins 0.64 secs\n",
            "Train Loss for batch 125/1358 @epoch2/2: 0.21237 in 0 mins 0.64 secs\n",
            "Train Loss for batch 150/1358 @epoch2/2: 0.1995 in 0 mins 0.62 secs\n",
            "Train Loss for batch 175/1358 @epoch2/2: 0.21555 in 0 mins 0.64 secs\n",
            "Train Loss for batch 200/1358 @epoch2/2: 0.19185 in 0 mins 0.64 secs\n",
            "Train Loss for batch 225/1358 @epoch2/2: 0.20674 in 0 mins 0.64 secs\n",
            "Train Loss for batch 250/1358 @epoch2/2: 0.2164 in 0 mins 0.65 secs\n",
            "Train Loss for batch 275/1358 @epoch2/2: 0.20615 in 0 mins 0.68 secs\n",
            "Train Loss for batch 300/1358 @epoch2/2: 0.19371 in 0 mins 0.64 secs\n",
            "Train Loss for batch 325/1358 @epoch2/2: 0.1961 in 0 mins 0.64 secs\n",
            "Train Loss for batch 350/1358 @epoch2/2: 0.20441 in 0 mins 0.64 secs\n",
            "Train Loss for batch 375/1358 @epoch2/2: 0.20822 in 0 mins 0.66 secs\n",
            "Train Loss for batch 400/1358 @epoch2/2: 0.19954 in 0 mins 0.67 secs\n",
            "Train Loss for batch 425/1358 @epoch2/2: 0.19445 in 0 mins 0.64 secs\n",
            "Train Loss for batch 450/1358 @epoch2/2: 0.20846 in 0 mins 0.63 secs\n",
            "Train Loss for batch 475/1358 @epoch2/2: 0.19778 in 0 mins 0.64 secs\n",
            "Train Loss for batch 500/1358 @epoch2/2: 0.20798 in 0 mins 0.64 secs\n",
            "Train Loss for batch 525/1358 @epoch2/2: 0.21381 in 0 mins 0.64 secs\n",
            "Train Loss for batch 550/1358 @epoch2/2: 0.20701 in 0 mins 0.65 secs\n",
            "Train Loss for batch 575/1358 @epoch2/2: 0.19258 in 0 mins 0.63 secs\n",
            "Train Loss for batch 600/1358 @epoch2/2: 0.20641 in 0 mins 0.67 secs\n",
            "Train Loss for batch 625/1358 @epoch2/2: 0.19556 in 0 mins 0.63 secs\n",
            "Train Loss for batch 650/1358 @epoch2/2: 0.20664 in 0 mins 0.63 secs\n",
            "Train Loss for batch 675/1358 @epoch2/2: 0.19437 in 0 mins 0.63 secs\n",
            "Train Loss for batch 700/1358 @epoch2/2: 0.20443 in 0 mins 0.64 secs\n",
            "Train Loss for batch 725/1358 @epoch2/2: 0.19843 in 0 mins 0.64 secs\n",
            "Train Loss for batch 750/1358 @epoch2/2: 0.20732 in 0 mins 0.65 secs\n",
            "Train Loss for batch 775/1358 @epoch2/2: 0.21007 in 0 mins 0.63 secs\n",
            "Train Loss for batch 800/1358 @epoch2/2: 0.19658 in 0 mins 0.65 secs\n",
            "Train Loss for batch 825/1358 @epoch2/2: 0.19325 in 0 mins 0.63 secs\n",
            "Train Loss for batch 850/1358 @epoch2/2: 0.20494 in 0 mins 0.63 secs\n",
            "Train Loss for batch 875/1358 @epoch2/2: 0.20874 in 0 mins 0.63 secs\n",
            "Train Loss for batch 900/1358 @epoch2/2: 0.19167 in 0 mins 0.66 secs\n",
            "Train Loss for batch 925/1358 @epoch2/2: 0.207 in 0 mins 0.63 secs\n",
            "Train Loss for batch 950/1358 @epoch2/2: 0.1842 in 0 mins 0.63 secs\n",
            "Train Loss for batch 975/1358 @epoch2/2: 0.19466 in 0 mins 0.65 secs\n",
            "Train Loss for batch 1000/1358 @epoch2/2: 0.19722 in 0 mins 0.62 secs\n",
            "Train Loss for batch 1025/1358 @epoch2/2: 0.20687 in 0 mins 0.63 secs\n",
            "Train Loss for batch 1050/1358 @epoch2/2: 0.1993 in 0 mins 0.64 secs\n",
            "Train Loss for batch 1075/1358 @epoch2/2: 0.19102 in 0 mins 0.65 secs\n",
            "Train Loss for batch 1100/1358 @epoch2/2: 0.19868 in 0 mins 0.62 secs\n",
            "Train Loss for batch 1125/1358 @epoch2/2: 0.19415 in 0 mins 0.63 secs\n",
            "Train Loss for batch 1150/1358 @epoch2/2: 0.20164 in 0 mins 0.65 secs\n",
            "Train Loss for batch 1175/1358 @epoch2/2: 0.18146 in 0 mins 0.65 secs\n",
            "Train Loss for batch 1200/1358 @epoch2/2: 0.20404 in 0 mins 0.65 secs\n",
            "Train Loss for batch 1225/1358 @epoch2/2: 0.20737 in 0 mins 0.64 secs\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kD3xZ1L1-BsU"
      },
      "source": [
        "!cp /content/models -r /content/drive/MyDrive/NIH_Dataset_total/folders/\n",
        "!cp /content/pickles -r /content/drive/MyDrive/NIH_Dataset_total/folders/\n",
        "!cp /content/GT_and_probs -r /content/drive/MyDrive/NIH_Dataset_total/folders/\n",
        "\n",
        "\n",
        "#!cp /content/drive/MyDrive/NIH_Dataset_total/folders/models -r /content/ \n",
        "#!cp /content/drive/MyDrive/NIH_Dataset_total/folders/pickles -r /content/\n",
        "#!cp /content/drive/MyDrive/NIH_Dataset_total/folders/GT_and_probs -r /content/"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DNbo3_LYNVzC"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mQbfkio39SWi"
      },
      "source": [
        "PATH = 'weightsDensenet_121_v1_2'\n",
        "torch.save(model.state_dict(), PATH)"
      ],
      "execution_count": 12,
      "outputs": []
    }
  ]
}